import operator
from typing import List, Annotated, Sequence
from typing_extensions import TypedDict
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, BaseMessage, AIMessage
from langgraph.graph import END, StateGraph

from chains import generate_chain, reflect_chain
import streamlit as st


# --- 1. ìƒíƒœì— 'ë‹¤ìŒ ê²½ë¡œ'ë¥¼ ì €ì¥í•  í•„ë“œ ì¶”ê°€ ---
class GraphState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]

# --- 2. ë…¸ë“œ ë° ì¡°ê±´ë¶€ ì—£ì§€ í•¨ìˆ˜ ì •ì˜ ---
def generate_node(state: GraphState):
    res = generate_chain.invoke({"messages": state["messages"]})
    return {"messages": [res]}

def reflect_node(state: GraphState):
    res = reflect_chain.invoke({"messages": state["messages"]})
    return {"messages": [HumanMessage(content=res.content)]}

# â—ìˆ˜ì •ë¨: í•¨ìˆ˜ì˜ ì´ë¦„ê³¼ ë¡œì§ì„ "ê²€í†  ê²°ê³¼ì— ë”°ë¼" ë¶„ê¸°í•˜ë„ë¡ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.
def grade_generation(state: GraphState):
    """
    Reflectorì˜ í”¼ë“œë°±ì„ í™•ì¸í•˜ì—¬ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤.
    - "ì„±ê³µ"ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ë˜í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
    - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, ë£¨í”„ë¥¼ ê³„ì†í•©ë‹ˆë‹¤.
    - ìµœëŒ€ 3ë²ˆì˜ ìˆ˜ì •-ê²€í†  ì‚¬ì´í´(ì´ ë©”ì‹œì§€ 6ê°œ)ì„ ì´ˆê³¼í•˜ë©´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤.
    """
    # ê°€ì¥ ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ Reflectorì˜ í”¼ë“œë°±ì…ë‹ˆë‹¤.
    last_message = state["messages"][-1]

    # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ ì¢…ë£Œ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    if len(state["messages"]) > 6:
        print("--- ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í•˜ì—¬ ì¢…ë£Œí•©ë‹ˆë‹¤. ---")
        return "end"

    # í”¼ë“œë°± ë‚´ìš©ì— "ì„±ê³µ"ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if "ì„±ê³µ" in last_message.content:
        print("--- ê²€í†  ê²°ê³¼ 'ì„±ê³µ'ì´ë¯€ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤. ---")
        return "end"
    else:
        print("--- ê²€í†  ê²°ê³¼ 'ì‹¤íŒ¨'ì´ë¯€ë¡œ ìˆ˜ì •ì„ ê³„ì†í•©ë‹ˆë‹¤. ---")
        return "continue"


# --- 3. ê·¸ë˜í”„ ìƒì„± ë° ì»´íŒŒì¼ ---
@st.cache_resource
def build_graph():
    # ìƒìˆ˜ ì •ì˜
    GENERATE = "generate"
    REFLECT = "reflect"

    builder = StateGraph(GraphState)

    builder.add_node(GENERATE, generate_node)
    builder.add_node(REFLECT, reflect_node)
    builder.set_entry_point(GENERATE)

    # â—ìˆ˜ì •ë¨: ê·¸ë˜í”„ íë¦„ì„ ì¬êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.
    # 1. ìƒì„±(GENERATE) í›„ì—ëŠ” í•­ìƒ ê²€í† (REFLECT)ë¡œ ê°‘ë‹ˆë‹¤.
    builder.add_edge(GENERATE, REFLECT)

    # 2. ê²€í† (REFLECT) í›„ì— ì¡°ê±´ë¶€ë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤.
    builder.add_conditional_edges(
        REFLECT,
        grade_generation, # ìƒˆë¡œìš´ ì¡°ê±´ í•¨ìˆ˜ ì‚¬ìš©
        {
            "continue": GENERATE, # 'continue'ë¥¼ ë°˜í™˜í•˜ë©´ ë‹¤ì‹œ GENERATEë¡œ
            "end": END            # 'end'ë¥¼ ë°˜í™˜í•˜ë©´ ì¢…ë£Œ
        }
    )

    graph = builder.compile()
    return graph


graph = build_graph()
load_dotenv()


# --- 4. Streamlit UI êµ¬ì„± ---
st.title("ğŸ¤– ë¬¸ì¥ ìˆ˜ì •ì„ ìœ„í•œ AI Agent")
st.markdown("### ë°œí‘œìë£Œ, ë³´ê³ ì„œ ë¬¸êµ¬ ë“±ì„ ì…ë ¥í•˜ë©´ AIê°€ ìŠ¤ìŠ¤ë¡œ ê²€í† í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤.")

# â—ìˆ˜ì •ë¨: ê°€ë…ì„±ì„ ìœ„í•´ ë…¸ë“œ ì´ë¦„ì„ ê·¸ë˜í”„ ë¹Œë” ì•ˆìœ¼ë¡œ ì˜®ê²¼ìŠµë‹ˆë‹¤.
NODE_NAME_MAP = {
    "generate": "ğŸ¤– AI ì´ˆì•ˆ ìƒì„±/ìˆ˜ì •",
    "reflect": "ğŸ§ AI ìì²´ ê²€í†  ë° í”¼ë“œë°±",
}

# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì„ í…ìŠ¤íŠ¸ ì˜ì—­
user_input = st.text_area("ìˆ˜ì •í•˜ê³  ì‹¶ì€ ì „ì²´ ë¬¸ì¥ì„ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:", height=150,
                          placeholder="ì—¬ê¸°ì— ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")


if st.button("AI ì‹¤í–‰í•˜ê¸°"):
    if not user_input:
        st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        initial_prompt = f"""ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ë¹„í‰í•˜ê³  ë” ë‚˜ì€ ë²„ì „ìœ¼ë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
            ---
            ì›ë³¸ í…ìŠ¤íŠ¸:
            {user_input}
            """
        # ì´ˆê¸° ì…ë ¥ê°’ ì„¤ì •
        initial_message = HumanMessage(content=initial_prompt)
        inputs = {"messages": [initial_message]}
        st.markdown("---")

        final_answer = ""
        # AIê°€ ì‘ì—…í•˜ëŠ” ë™ì•ˆ ìŠ¤í”¼í„° í‘œì‹œ
        with st.spinner("AI ì—ì´ì „íŠ¸ê°€ ìƒê°ì¤‘ì…ë‹ˆë‹¤..."):
            # streamì„ ì‚¬ìš©í•´ ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ìŒ
            for step in graph.stream(inputs, {"recursion_limit": 10}):
                # stepì€ {"node_name": state} í˜•íƒœì˜ ë””ì…”ë„ˆë¦¬ì„
                node_name = list(step.keys())[0]
                state = list(step.values())[0]
                display_name = NODE_NAME_MAP.get(node_name)

                if display_name:
                    st.subheader(display_name)
                    last_message = state["messages"][-1]
                    if isinstance(last_message, HumanMessage):
                        st.info(f"ğŸ‘¤ **[AIì˜ ìì²´ í”¼ë“œë°±]**\n\n{last_message.content}")
                    elif isinstance(last_message, AIMessage):
                        st.success(f"ğŸ¤– **[AIì˜ ìƒì„±/ìˆ˜ì •ì•ˆ]**\n\n{last_message.content}")
                        # â—ìˆ˜ì •ë¨: AIê°€ ë‹µë³€ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ ê·¸ ë‚´ìš©ì„ final_answerì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                        final_answer = last_message.content

                #final_state = state

        st.markdown("---")
        st.header("âœ… ìµœì¢… ê²°ê³¼")
       # â—ìˆ˜ì •ë¨: ë£¨í”„ê°€ ëë‚œ í›„, ì €ì¥í•´ ë‘” ë§ˆì§€ë§‰ AI ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        if final_answer:
            st.markdown(final_answer)
        else:
            st.error("ìµœì¢… ê²°ê³¼ë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")







